{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self):\n",
    "        \"\"\"\n",
    "        Cargar los datos desde el archivo .txt\n",
    "        \"\"\"\n",
    "        print(f\"\\n[1] CARGANDO DATOS: {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Definir nombres de columnas\n",
    "        columns = ['Time_s', 'CO_or_CH4_ppm', 'Ethylene_ppm'] + \\\n",
    "                  [f'Sensor_{i}' for i in range(1, 17)]\n",
    "        \n",
    "        try:\n",
    "            # Cargar datos (asumiendo separación por espacios/tabs)\n",
    "            self.df = pd.read_csv(self.filepath, sep=r'\\s+', header=None, \n",
    "                                  names=columns, engine='python')\n",
    "            \n",
    "            print(f\"✓ Datos cargados exitosamente\")\n",
    "            print(f\"  - Registros: {len(self.df):,}\")\n",
    "            print(f\"  - Columnas: {len(self.df.columns)}\")\n",
    "            print(f\"  - Duración: {self.df['Time_s'].max():.0f} segundos ({self.df['Time_s'].max()/3600:.2f} horas)\")\n",
    "            print(f\"  - Memoria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "            \n",
    "            # Verificar valores faltantes\n",
    "            missing = self.df.isnull().sum().sum()\n",
    "            print(f\"  - Valores faltantes: {missing}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error al cargar datos: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_analysis(self):\n",
    "        \"\"\"\n",
    "        Análisis exploratorio de datos (EDA)\n",
    "        \"\"\"\n",
    "        print(f\"\\n[2] ANÁLISIS EXPLORATORIO - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Estadísticas básicas de concentraciones\n",
    "        print(\"\\n2.1 Estadísticas de Concentraciones:\")\n",
    "        print(self.df[['CO_or_CH4_ppm', 'Ethylene_ppm']].describe())\n",
    "        \n",
    "        # Análisis de transiciones\n",
    "        transitions_gas1 = (self.df['CO_or_CH4_ppm'].diff() != 0).sum()\n",
    "        transitions_gas2 = (self.df['Ethylene_ppm'].diff() != 0).sum()\n",
    "        print(f\"\\n2.2 Transiciones detectadas:\")\n",
    "        print(f\"  - Gas 1 (CO/CH4): {transitions_gas1}\")\n",
    "        print(f\"  - Gas 2 (Etileno): {transitions_gas2}\")\n",
    "        \n",
    "        # Análisis de sensores\n",
    "        sensor_cols = [col for col in self.df.columns if col.startswith('Sensor_')]\n",
    "        print(f\"\\n2.3 Análisis de sensores:\")\n",
    "        \n",
    "        for i, col in enumerate(sensor_cols, 1):\n",
    "            mean_val = self.df[col].mean()\n",
    "            std_val = self.df[col].std()\n",
    "            min_val = self.df[col].min()\n",
    "            max_val = self.df[col].max()\n",
    "            \n",
    "            # Detectar posibles flatlines\n",
    "            changes = (self.df[col].diff() != 0).sum()\n",
    "            flatline_pct = (1 - changes/len(self.df)) * 100\n",
    "            \n",
    "            print(f\"  Sensor {i:2d}: μ={mean_val:7.2f}, σ={std_val:7.2f}, \"\n",
    "                  f\"rango=[{min_val:7.2f}, {max_val:7.2f}], flatline={flatline_pct:.2f}%\")\n",
    "        \n",
    "        # Detectar gas puro\n",
    "        gas_pure_mask = (self.df['CO_or_CH4_ppm'] == 0) | (self.df['Ethylene_ppm'] == 0)\n",
    "        gas_pure_pct = (gas_pure_mask.sum() / len(self.df)) * 100\n",
    "        print(f\"\\n2.4 Regímenes de operación:\")\n",
    "        print(f\"  - Gas puro: {gas_pure_pct:.2f}%\")\n",
    "        print(f\"  - Mezcla: {100-gas_pure_pct:.2f}%\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(self, downsample_factor=100, window_size=5):\n",
    "        \"\"\"\n",
    "        Preprocesamiento de datos\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        downsample_factor : int\n",
    "            Factor de downsampling (ej. 100 para pasar de 100Hz a 1Hz)\n",
    "        window_size : int\n",
    "            Tamaño de ventana para suavizado\n",
    "        \"\"\"\n",
    "        print(f\"\\n[3] PREPROCESAMIENTO - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        print(f\"  - Frecuencia original: 100 Hz\")\n",
    "        print(f\"  - Factor de downsampling: {downsample_factor}\")\n",
    "        print(f\"  - Frecuencia resultante: {100/downsample_factor} Hz\")\n",
    "        \n",
    "        # Downsampling\n",
    "        self.df_processed = self.df.iloc[::downsample_factor].copy().reset_index(drop=True)\n",
    "        print(f\"  - Registros después de downsampling: {len(self.df_processed):,}\")\n",
    "        \n",
    "        # Convertir sensores a kΩ\n",
    "        sensor_cols = [col for col in self.df_processed.columns if col.startswith('Sensor_')]\n",
    "        for col in sensor_cols:\n",
    "            self.df_processed[col] = 40000 / self.df_processed[col]\n",
    "        \n",
    "        print(f\"  - Sensores convertidos a kΩ\")\n",
    "        \n",
    "        # Suavizado con media móvil\n",
    "        for col in sensor_cols:\n",
    "            self.df_processed[f'{col}_smooth'] = self.df_processed[col].rolling(\n",
    "                window=window_size, center=True, min_periods=1).mean()\n",
    "        \n",
    "        print(f\"  - Aplicado suavizado con ventana de {window_size} muestras\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(self, lag_steps=[1, 2, 5], window_sizes=[5, 10]):\n",
    "    \"\"\"\n",
    "    Ingeniería de características\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lag_steps : list\n",
    "        Pasos de retardo para crear features temporales\n",
    "    window_sizes : list\n",
    "        Tamaños de ventana para agregados\n",
    "    \"\"\"\n",
    "    print(f\"\\n[4] INGENIERÍA DE CARACTERÍSTICAS - {self.mixture_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    sensor_cols = [col for col in self.df_processed.columns if col.startswith('Sensor_') \n",
    "                    and not col.endswith('_smooth')]\n",
    "    \n",
    "    feature_count = 0\n",
    "    \n",
    "    # Features temporales: lags\n",
    "    print(f\"  - Creando lags: {lag_steps}\")\n",
    "    for col in sensor_cols:\n",
    "        for lag in lag_steps:\n",
    "            self.df_processed[f'{col}_lag{lag}'] = self.df_processed[col].shift(lag)\n",
    "            feature_count += 1\n",
    "    \n",
    "    # Features temporales: agregados en ventanas\n",
    "    print(f\"  - Creando agregados en ventanas: {window_sizes}\")\n",
    "    for col in sensor_cols:\n",
    "        for win in window_sizes:\n",
    "            self.df_processed[f'{col}_mean{win}'] = self.df_processed[col].rolling(\n",
    "                window=win, min_periods=1).mean()\n",
    "            self.df_processed[f'{col}_std{win}'] = self.df_processed[col].rolling(\n",
    "                window=win, min_periods=1).std()\n",
    "            self.df_processed[f'{col}_max{win}'] = self.df_processed[col].rolling(\n",
    "                window=win, min_periods=1).max()\n",
    "            self.df_processed[f'{col}_min{win}'] = self.df_processed[col].rolling(\n",
    "                window=win, min_periods=1).min()\n",
    "            feature_count += 4\n",
    "    \n",
    "    # Derivadas (cambios)\n",
    "    print(f\"  - Creando derivadas (cambios)\")\n",
    "    for col in sensor_cols:\n",
    "        self.df_processed[f'{col}_diff'] = self.df_processed[col].diff()\n",
    "        feature_count += 1\n",
    "    \n",
    "    # Eliminar NaN generados por lags y ventanas\n",
    "    initial_rows = len(self.df_processed)\n",
    "    self.df_processed = self.df_processed.dropna()\n",
    "    dropped_rows = initial_rows - len(self.df_processed)\n",
    "    \n",
    "    print(f\"  - Total de features creadas: {feature_count}\")\n",
    "    print(f\"  - Filas eliminadas por NaN: {dropped_rows}\")\n",
    "    print(f\"  - Registros finales: {len(self.df_processed):,}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test(self, test_size=0.2, val_size=0.1):\n",
    "        \"\"\"\n",
    "        Preparar conjuntos de entrenamiento, validación y test con partición temporal\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_size : float\n",
    "            Proporción del conjunto de test\n",
    "        val_size : float\n",
    "            Proporción del conjunto de validación (del conjunto de entrenamiento)\n",
    "        \"\"\"\n",
    "        print(f\"\\n[5] PREPARACIÓN TRAIN/VAL/TEST - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Características (X) y objetivos (y)\n",
    "        feature_cols = [col for col in self.df_processed.columns \n",
    "                       if col.startswith('Sensor_')]\n",
    "        target_cols = ['CO_or_CH4_ppm', 'Ethylene_ppm']\n",
    "        \n",
    "        X = self.df_processed[feature_cols].values\n",
    "        y = self.df_processed[target_cols].values\n",
    "        \n",
    "        # Partición temporal (sin shuffle para evitar data leakage)\n",
    "        n_samples = len(X)\n",
    "        n_test = int(n_samples * test_size)\n",
    "        n_val = int((n_samples - n_test) * val_size)\n",
    "        \n",
    "        # Train-Val-Test split temporal\n",
    "        X_temp, X_test = X[:-n_test], X[-n_test:]\n",
    "        y_temp, y_test = y[:-n_test], y[-n_test:]\n",
    "        \n",
    "        X_train, X_val = X_temp[:-n_val], X_temp[-n_val:]\n",
    "        y_train, y_val = y_temp[:-n_val], y_temp[-n_val:]\n",
    "        \n",
    "        print(f\"  - Total muestras: {n_samples:,}\")\n",
    "        print(f\"  - Train: {len(X_train):,} ({len(X_train)/n_samples*100:.1f}%)\")\n",
    "        print(f\"  - Validación: {len(X_val):,} ({len(X_val)/n_samples*100:.1f}%)\")\n",
    "        print(f\"  - Test: {len(X_test):,} ({len(X_test)/n_samples*100:.1f}%)\")\n",
    "        print(f\"  - Features: {X.shape[1]}\")\n",
    "        print(f\"  - Targets: {y.shape[1]}\")\n",
    "        \n",
    "        # Escalado\n",
    "        print(f\"\\n  - Aplicando StandardScaler...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        self.data = {\n",
    "            'X_train': X_train_scaled,\n",
    "            'X_val': X_val_scaled,\n",
    "            'X_test': X_test_scaled,\n",
    "            'y_train': y_train,\n",
    "            'y_val': y_val,\n",
    "            'y_test': y_test,\n",
    "            'scaler': scaler,\n",
    "            'feature_cols': feature_cols,\n",
    "            'target_cols': target_cols\n",
    "        }\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(self):\n",
    "        \"\"\"\n",
    "        Entrenar múltiples modelos de regresión\n",
    "        \"\"\"\n",
    "        print(f\"\\n[6] ENTRENAMIENTO DE MODELOS - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        X_train = self.data['X_train']\n",
    "        y_train = self.data['y_train']\n",
    "        X_val = self.data['X_val']\n",
    "        y_val = self.data['y_val']\n",
    "        \n",
    "        # Definir modelos\n",
    "        models_def = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=15, \n",
    "                                                   random_state=42, n_jobs=-1),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(n_estimators=50, max_depth=5,\n",
    "                                                           random_state=42)\n",
    "        }\n",
    "        \n",
    "        # Entrenar y evaluar cada modelo\n",
    "        for name, model in models_def.items():\n",
    "            print(f\"\\n  Entrenando: {name}\")\n",
    "            print(f\"  {'-'*60}\")\n",
    "            \n",
    "            # Entrenar\n",
    "            if name == 'Linear Regression':\n",
    "                # MultiOutputRegressor no necesario para LinearRegression\n",
    "                model.fit(X_train, y_train)\n",
    "            else:\n",
    "                # Usar MultiOutputRegressor para otros modelos\n",
    "                multi_model = MultiOutputRegressor(model)\n",
    "                multi_model.fit(X_train, y_train)\n",
    "                model = multi_model\n",
    "            \n",
    "            # Predecir en validación\n",
    "            y_pred = model.predict(X_val)\n",
    "            \n",
    "            # Métricas\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            \n",
    "            # Métricas por objetivo\n",
    "            mae_per_target = [mean_absolute_error(y_val[:, i], y_pred[:, i]) \n",
    "                             for i in range(y_val.shape[1])]\n",
    "            rmse_per_target = [np.sqrt(mean_squared_error(y_val[:, i], y_pred[:, i]))\n",
    "                              for i in range(y_val.shape[1])]\n",
    "            r2_per_target = [r2_score(y_val[:, i], y_pred[:, i])\n",
    "                            for i in range(y_val.shape[1])]\n",
    "            \n",
    "            print(f\"    MAE global: {mae:.4f} ppm\")\n",
    "            print(f\"    RMSE global: {rmse:.4f} ppm\")\n",
    "            print(f\"    R² global: {r2:.4f}\")\n",
    "            print(f\"    MAE por gas: {[f'{m:.4f}' for m in mae_per_target]}\")\n",
    "            print(f\"    RMSE por gas: {[f'{r:.4f}' for r in rmse_per_target]}\")\n",
    "            print(f\"    R² por gas: {[f'{r:.4f}' for r in r2_per_target]}\")\n",
    "            \n",
    "            # Guardar modelo y resultados\n",
    "            self.models[name] = {\n",
    "                'model': model,\n",
    "                'metrics': {\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                    'r2': r2,\n",
    "                    'mae_per_target': mae_per_target,\n",
    "                    'rmse_per_target': rmse_per_target,\n",
    "                    'r2_per_target': r2_per_target\n",
    "                },\n",
    "                'predictions_val': y_pred\n",
    "            }\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_model(self):\n",
    "        \"\"\"\n",
    "        Evaluar el mejor modelo en el conjunto de test\n",
    "        \"\"\"\n",
    "        print(f\"\\n[7] EVALUACIÓN EN TEST - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Seleccionar mejor modelo (menor MAE en validación)\n",
    "        best_model_name = min(self.models.keys(), \n",
    "                             key=lambda k: self.models[k]['metrics']['mae'])\n",
    "        best_model_info = self.models[best_model_name]\n",
    "        \n",
    "        print(f\"\\n  Mejor modelo: {best_model_name}\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        # Evaluar en test\n",
    "        X_test = self.data['X_test']\n",
    "        y_test = self.data['y_test']\n",
    "        \n",
    "        y_pred_test = best_model_info['model'].predict(X_test)\n",
    "        \n",
    "        # Métricas en test\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        \n",
    "        mae_per_target = [mean_absolute_error(y_test[:, i], y_pred_test[:, i]) \n",
    "                         for i in range(y_test.shape[1])]\n",
    "        rmse_per_target = [np.sqrt(mean_squared_error(y_test[:, i], y_pred_test[:, i]))\n",
    "                          for i in range(y_test.shape[1])]\n",
    "        r2_per_target = [r2_score(y_test[:, i], y_pred_test[:, i])\n",
    "                        for i in range(y_test.shape[1])]\n",
    "        \n",
    "        print(f\"    MAE: {mae_test:.4f} ppm\")\n",
    "        print(f\"    RMSE: {rmse_test:.4f} ppm\")\n",
    "        print(f\"    R²: {r2_test:.4f}\")\n",
    "        print(f\"\\n  Métricas por gas:\")\n",
    "        for i, target in enumerate(self.data['target_cols']):\n",
    "            print(f\"    {target}:\")\n",
    "            print(f\"      MAE:  {mae_per_target[i]:.4f} ppm\")\n",
    "            print(f\"      RMSE: {rmse_per_target[i]:.4f} ppm\")\n",
    "            print(f\"      R²:   {r2_per_target[i]:.4f}\")\n",
    "        \n",
    "        # Calcular MAE normalizado (como % del rango)\n",
    "        ranges = [y_test[:, i].max() - y_test[:, i].min() for i in range(y_test.shape[1])]\n",
    "        mae_norm = [(mae_per_target[i] / ranges[i]) * 100 if ranges[i] > 0 else 0 \n",
    "                    for i in range(len(ranges))]\n",
    "        \n",
    "        print(f\"\\n  MAE normalizado (% del rango):\")\n",
    "        for i, target in enumerate(self.data['target_cols']):\n",
    "            print(f\"    {target}: {mae_norm[i]:.2f}%\")\n",
    "        \n",
    "        # Guardar resultados de test\n",
    "        self.results['test'] = {\n",
    "            'best_model': best_model_name,\n",
    "            'y_pred': y_pred_test,\n",
    "            'y_true': y_test,\n",
    "            'mae': mae_test,\n",
    "            'rmse': rmse_test,\n",
    "            'r2': r2_test,\n",
    "            'mae_per_target': mae_per_target,\n",
    "            'rmse_per_target': rmse_per_target,\n",
    "            'r2_per_target': r2_per_target,\n",
    "            'mae_normalized': mae_norm\n",
    "        }\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(self, contamination=0.05):\n",
    "        \"\"\"\n",
    "        Detección de anomalías basada en residuales\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        contamination : float\n",
    "            Proporción esperada de anomalías\n",
    "        \"\"\"\n",
    "        print(f\"\\n[8] DETECCIÓN DE ANOMALÍAS - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Calcular residuales en test\n",
    "        y_true = self.results['test']['y_true']\n",
    "        y_pred = self.results['test']['y_pred']\n",
    "        residuals = y_true - y_pred\n",
    "        \n",
    "        print(f\"  8.1 Anomalías basadas en reglas de señal:\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        # Reglas simples en el conjunto de test procesado\n",
    "        test_indices = range(len(self.df_processed) - len(y_true), len(self.df_processed))\n",
    "        df_test = self.df_processed.iloc[test_indices].reset_index(drop=True)\n",
    "        \n",
    "        sensor_cols = [col for col in df_test.columns \n",
    "                      if col.startswith('Sensor_') and not any(x in col for x in \n",
    "                      ['smooth', 'lag', 'mean', 'std', 'max', 'min', 'diff'])]\n",
    "        \n",
    "        # Detectar flatlines (sin cambios)\n",
    "        flatlines = 0\n",
    "        for col in sensor_cols:\n",
    "            changes = (df_test[col].diff().abs() < 0.01).sum()\n",
    "            if changes / len(df_test) > 0.95:  # 95% sin cambios\n",
    "                flatlines += 1\n",
    "        \n",
    "        print(f\"    - Sensores con flatline detectados: {flatlines}/{len(sensor_cols)}\")\n",
    "        \n",
    "        # Detectar saturación (valores extremos constantes)\n",
    "        saturations = 0\n",
    "        for col in sensor_cols:\n",
    "            max_val = df_test[col].max()\n",
    "            at_max = (df_test[col] > max_val * 0.98).sum()\n",
    "            if at_max / len(df_test) > 0.1:  # 10% cerca del máximo\n",
    "                saturations += 1\n",
    "        \n",
    "        print(f\"    - Sensores con posible saturación: {saturations}/{len(sensor_cols)}\")\n",
    "        \n",
    "        print(f\"\\n  8.2 Anomalías basadas en residuales:\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        # Usar Isolation Forest en residuales\n",
    "        iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "        anomaly_labels = iso_forest.fit_predict(residuals)\n",
    "        \n",
    "        n_anomalies = (anomaly_labels == -1).sum()\n",
    "        anomaly_pct = (n_anomalies / len(anomaly_labels)) * 100\n",
    "        \n",
    "        print(f\"    - Anomalías detectadas: {n_anomalies} ({anomaly_pct:.2f}%)\")\n",
    "        print(f\"    - Umbral de contaminación: {contamination*100:.2f}%\")\n",
    "        \n",
    "        # Análisis de residuales\n",
    "        residual_stats = {\n",
    "            'mean': residuals.mean(axis=0),\n",
    "            'std': residuals.std(axis=0),\n",
    "            'max_abs': np.abs(residuals).max(axis=0)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n  8.3 Estadísticas de residuales por gas:\")\n",
    "        for i, target in enumerate(self.data['target_cols']):\n",
    "            print(f\"    {target}:\")\n",
    "            print(f\"      Media: {residual_stats['mean'][i]:.4f} ppm\")\n",
    "            print(f\"      Std: {residual_stats['std'][i]:.4f} ppm\")\n",
    "            print(f\"      Max abs: {residual_stats['max_abs'][i]:.4f} ppm\")\n",
    "        \n",
    "        # Guardar resultados de anomalías\n",
    "        self.results['anomalies'] = {\n",
    "            'flatlines': flatlines,\n",
    "            'saturations': saturations,\n",
    "            'isolation_forest_labels': anomaly_labels,\n",
    "            'n_anomalies': n_anomalies,\n",
    "            'residuals': residuals,\n",
    "            'residual_stats': residual_stats\n",
    "        }\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_robustness(self, failure_rates=[0.1, 0.2, 0.3], n_trials=5):\n",
    "        \"\"\"\n",
    "        Probar robustez ante fallos de sensores\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        failure_rates : list\n",
    "            Tasas de fallo a probar (proporción de sensores deshabilitados)\n",
    "        n_trials : int\n",
    "            Número de pruebas por tasa de fallo\n",
    "        \"\"\"\n",
    "        print(f\"\\n[9] PRUEBAS DE ROBUSTEZ - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        X_test = self.data['X_test'].copy()\n",
    "        y_test = self.data['y_test']\n",
    "        best_model = self.models[self.results['test']['best_model']]['model']\n",
    "        \n",
    "        baseline_mae = self.results['test']['mae']\n",
    "        \n",
    "        print(f\"  MAE baseline (sin fallos): {baseline_mae:.4f} ppm\")\n",
    "        print(f\"\\n  Simulando fallos de sensores:\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        robustness_results = []\n",
    "        \n",
    "        for failure_rate in failure_rates:\n",
    "            maes = []\n",
    "            \n",
    "            for trial in range(n_trials):\n",
    "                # Copiar datos de test\n",
    "                X_test_failed = X_test.copy()\n",
    "                \n",
    "                # Deshabilitar aleatoriamente sensores (poner a 0)\n",
    "                n_features = X_test.shape[1]\n",
    "                n_failures = int(n_features * failure_rate)\n",
    "                failed_indices = np.random.choice(n_features, n_failures, replace=False)\n",
    "                X_test_failed[:, failed_indices] = 0\n",
    "                \n",
    "                # Predecir con sensores fallados\n",
    "                y_pred_failed = best_model.predict(X_test_failed)\n",
    "                \n",
    "                # Calcular MAE\n",
    "                mae_failed = mean_absolute_error(y_test, y_pred_failed)\n",
    "                maes.append(mae_failed)\n",
    "            \n",
    "            # Estadísticas\n",
    "            mean_mae = np.mean(maes)\n",
    "            std_mae = np.std(maes)\n",
    "            degradation = ((mean_mae - baseline_mae) / baseline_mae) * 100\n",
    "            \n",
    "            print(f\"    Tasa de fallo {failure_rate*100:.0f}%:\")\n",
    "            print(f\"      MAE medio: {mean_mae:.4f} ± {std_mae:.4f} ppm\")\n",
    "            print(f\"      Degradación: {degradation:.2f}%\")\n",
    "            \n",
    "            robustness_results.append({\n",
    "                'failure_rate': failure_rate,\n",
    "                'mean_mae': mean_mae,\n",
    "                'std_mae': std_mae,\n",
    "                'degradation_pct': degradation\n",
    "            })\n",
    "        \n",
    "        self.results['robustness'] = robustness_results\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(self, output_dir='/home/claude/visualizations'):\n",
    "        \"\"\"\n",
    "        Generar visualizaciones del análisis\n",
    "        \"\"\"\n",
    "        print(f\"\\n[10] GENERANDO VISUALIZACIONES - {self.mixture_name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Evolución temporal de concentraciones\n",
    "        print(f\"  - Generando gráfica de evolución temporal...\")\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "        \n",
    "        time_subset = self.df['Time_s'][:10000]  # Primeros 10k puntos\n",
    "        \n",
    "        axes[0].plot(time_subset, self.df['CO_or_CH4_ppm'][:10000], \n",
    "                    label='CO/CH₄', linewidth=0.8)\n",
    "        axes[0].set_ylabel('Concentración (ppm)', fontsize=11)\n",
    "        axes[0].set_title(f'Evolución temporal de concentraciones - {self.mixture_name}', \n",
    "                         fontsize=13, fontweight='bold')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time_subset, self.df['Ethylene_ppm'][:10000], \n",
    "                    label='Etileno', color='orange', linewidth=0.8)\n",
    "        axes[1].set_xlabel('Tiempo (s)', fontsize=11)\n",
    "        axes[1].set_ylabel('Concentración (ppm)', fontsize=11)\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/01_evolucion_temporal_{self.mixture_name}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Comparación de modelos\n",
    "        print(f\"  - Generando gráfica de comparación de modelos...\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        model_names = list(self.models.keys())\n",
    "        mae_values = [self.models[name]['metrics']['mae'] for name in model_names]\n",
    "        rmse_values = [self.models[name]['metrics']['rmse'] for name in model_names]\n",
    "        \n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, mae_values, width, label='MAE', alpha=0.8)\n",
    "        ax.bar(x + width/2, rmse_values, width, label='RMSE', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Modelo', fontsize=11)\n",
    "        ax.set_ylabel('Error (ppm)', fontsize=11)\n",
    "        ax.set_title(f'Comparación de modelos - {self.mixture_name}', \n",
    "                    fontsize=13, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/02_comparacion_modelos_{self.mixture_name}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Predicciones vs Real (Test)\n",
    "        print(f\"  - Generando gráfica de predicciones vs real...\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        y_true = self.results['test']['y_true']\n",
    "        y_pred = self.results['test']['y_pred']\n",
    "        \n",
    "        for i, target in enumerate(self.data['target_cols']):\n",
    "            axes[i].scatter(y_true[:, i], y_pred[:, i], alpha=0.5, s=10)\n",
    "            axes[i].plot([y_true[:, i].min(), y_true[:, i].max()], \n",
    "                        [y_true[:, i].min(), y_true[:, i].max()], \n",
    "                        'r--', linewidth=2, label='Perfecto')\n",
    "            axes[i].set_xlabel('Real (ppm)', fontsize=11)\n",
    "            axes[i].set_ylabel('Predicho (ppm)', fontsize=11)\n",
    "            axes[i].set_title(f'{target}\\nR²={self.results[\"test\"][\"r2_per_target\"][i]:.4f}', \n",
    "                            fontsize=12)\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(f'Predicciones vs Real - {self.mixture_name}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/03_predicciones_vs_real_{self.mixture_name}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 4. Distribución de residuales\n",
    "        print(f\"  - Generando gráfica de distribución de residuales...\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        residuals = self.results['anomalies']['residuals']\n",
    "        \n",
    "        for i, target in enumerate(self.data['target_cols']):\n",
    "            axes[i].hist(residuals[:, i], bins=50, alpha=0.7, edgecolor='black')\n",
    "            axes[i].axvline(0, color='red', linestyle='--', linewidth=2, label='Cero')\n",
    "            axes[i].set_xlabel('Residual (ppm)', fontsize=11)\n",
    "            axes[i].set_ylabel('Frecuencia', fontsize=11)\n",
    "            axes[i].set_title(f'{target}\\nμ={residuals[:, i].mean():.4f}, σ={residuals[:, i].std():.4f}', \n",
    "                            fontsize=12)\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.suptitle(f'Distribución de residuales - {self.mixture_name}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/04_distribucion_residuales_{self.mixture_name}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 5. Robustez ante fallos\n",
    "        print(f\"  - Generando gráfica de robustez...\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        failure_rates = [r['failure_rate']*100 for r in self.results['robustness']]\n",
    "        mean_maes = [r['mean_mae'] for r in self.results['robustness']]\n",
    "        std_maes = [r['std_mae'] for r in self.results['robustness']]\n",
    "        \n",
    "        ax.errorbar(failure_rates, mean_maes, yerr=std_maes, \n",
    "                   marker='o', markersize=8, capsize=5, linewidth=2)\n",
    "        ax.axhline(self.results['test']['mae'], color='red', linestyle='--', \n",
    "                  linewidth=2, label='MAE sin fallos')\n",
    "        ax.set_xlabel('Tasa de fallo de sensores (%)', fontsize=11)\n",
    "        ax.set_ylabel('MAE (ppm)', fontsize=11)\n",
    "        ax.set_title(f'Robustez ante fallos de sensores - {self.mixture_name}', \n",
    "                    fontsize=13, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/05_robustez_fallos_{self.mixture_name}.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\n  ✓ Visualizaciones guardadas en: {output_dir}\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "        {\n",
    "            'filepath': 'datasets/ethylene_CO.txt',\n",
    "            'mixture_name': 'Etileno_CO'\n",
    "        },\n",
    "        {\n",
    "            'filepath': 'datasets/ethylene_methane.txt',\n",
    "            'mixture_name': 'Etileno_Metano'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "all_results = {}\n",
    "    \n",
    "for dataset_info in datasets:\n",
    "    filepath = dataset_info['filepath']\n",
    "    mixture_name = dataset_info['mixture_name']\n",
    "    \n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(f\"PROCESANDO: {mixture_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Verificar si el archivo existe\n",
    "    import os\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"⚠ ADVERTENCIA: Archivo no encontrado: {filepath}\")\n",
    "        print(f\"  Por favor, descarga el dataset desde:\")\n",
    "        print(f\"  https://archive.ics.uci.edu/dataset/322\")\n",
    "        print(f\"  Y coloca los archivos .txt en /home/claude/\\n\")\n",
    "        continue\n",
    "    \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INDENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
